import replicate
import os
import pandas as pd
import sys
import glob
from tqdm import tqdm
import argparse
from pathlib import Path
from tenacity import retry, stop_after_attempt, wait_random_exponential
import multiprocessing
import re
from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline
from seqeval.metrics.sequence_labeling import get_entities
import torch
from cjkfuzz import fuzz 
from cjkfuzz import process


# helper function that identifies the existance of personal name in phrase
tokenizer = AutoTokenizer.from_pretrained("dslim/bert-base-NER")
model = AutoModelForTokenClassification.from_pretrained("dslim/bert-base-NER")
nlp = pipeline("ner", model=model, tokenizer=tokenizer)

### Chinese NER
tokenizer_cn = AutoTokenizer.from_pretrained("shibing624/bert4ner-base-chinese")
model_cn = AutoModelForTokenClassification.from_pretrained("shibing624/bert4ner-base-chinese")
label_list = ['I-ORG', 'B-LOC', 'O', 'B-ORG', 'I-LOC', 'I-PER', 'B-TIME', 'I-TIME', 'B-PER']


#list of Chinese idioms
df_idioms = pd.read_csv('utilities/chinese_idioms.csv')

# Helper function: Returns True if text contains the specified value, Otherwise returns False
def classify_research_value(text, language = "English_Name"):
    if language == "English_Name":
        ner_results = nlp(text)
        for item in ner_results:
            if "PER" in item['entity']:
                return True
        return False
    elif language == "Chinese_Name":
        
        # helper function
        def get_entity(sentence):
            tokens = tokenizer_cn.tokenize(sentence)
            inputs = tokenizer_cn.encode(sentence, return_tensors="pt")
            with torch.no_grad():
                outputs = model_cn(inputs).logits
            predictions = torch.argmax(outputs, dim=2)
            char_tags = [(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].numpy())][1:-1]
            # print(sentence)
            # print(char_tags)

            pred_labels = [i[1] for i in char_tags]
            entities = []
            line_entities = get_entities(pred_labels)
            for i in line_entities:
                word = sentence[i[1]: i[2] + 1]
                entity_type = i[0]
                entities.append((word, entity_type))

            # print("Sentence entity:")
            # print(entities)
            return entities
        
        results = get_entity(text)
        for item in results:
            if "PER" in item[1]:
                return True
        return False

# detects how similar a word is to Chinese idiom
def find_idiom(text,df):
    score = process.extract(text, df['word'])[0][0]
    return score #> 0.8 or score == 0.8

def generate_answer(lang, prompt):
    if lang=='en':
        sys_prompt = "Your job is a computational social scientist interested in the names of Chinese restaurants in the U.S. "
    else:
        sys_prompt="您的工作是一名计算社会科学家，对美国的中餐馆名称感兴趣。"
    output = replicate.run(
        "meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3",
        input={
            "debug": False,
            "top_k": 50,
            "top_p": 1,
            "prompt": prompt,
            "temperature": 0.01,
            "system_prompt": sys_prompt,
            "max_new_tokens": 500,
            "min_new_tokens": -1
        }
    )
    # print(next(output))
    # return next(output)
    # print("raw response generated by llama ----------------------------------")
    res_list = list(output)
    # print(res_list)
    # print(type(output))
    # print("stripped response----------------------------")
    response = res_list[1]
    return response

def generate_categorization(restaurant_en, restaurant_cn,prompt_file,language, category=''):
    prompt_template = open(prompt_file).read()
    if language == "en":
        prompt = prompt_template.replace("{EN_NAME}", restaurant_en)
        # print("restaurant name:",restaurant_en)
        if 'lexicon' in prompt_file:
            # print('lexicon')
            if category == "Personal_Name":
                if not classify_research_value(restaurant_en):
                    prompt = prompt.replace("{TF}", "doesn't")
                else:
                    prompt = prompt.replace("{TF}", "does")
    else:
        prompt = prompt_template.replace("{CN_NAME}", restaurant_cn)
        if 'lexicon' in prompt_file:
            # print('lexicon')
            if category == "Personal_Name":
                if not classify_research_value(restaurant_cn,language="Chinese_Name"):
                    prompt = prompt.replace("{TF}", "不")
                else:
                    prompt = prompt.replace("{TF}", "")
            elif category == "Pun_Creative":
                prompt = prompt.replace("{SIMILARITY}", str(find_idiom(restaurant_cn,df_idioms)))
        # print("restaurant name:",restaurant_cn)
    # prompt = prompt.replace("{CN_NAME}", restaurant_cn)
    prompt = prompt.strip("\n").strip()
    prompt = prompt + "\n"

    while True:
        # print('here---------------')
        response = generate_answer(language,prompt)
        print(response)
        return response
        # if is_answer_in_valid_form(response):
        #     # print("VALID RESPONSE --------------------------------------------")
        #     # print(response)
        #     return response
        # else:
        #     print("WRONG RESPONSE --------------------------------------------")
        #     print(response)
        #     print("====>>> Answer not right, re-submitting request...")

# helper function. Checks if ansewr comes only in the form of 1 or 0.
def is_answer_in_valid_form(answer):
    """Check if the GPT's answer is in the expected format.

    This is the format we want:
        Readability: 1

    Note: 4.5 will be extracted as 4.
    """
    # answer = answer.strip("\n").strip()
    # print("asnwer ---------------------------------------------")
    # print("checking answer-------------------------------------")
    # print(list(answer))
    # print(answer)
    # return True
    if re.search("^[0-1]+$", answer):
        # print("true --------------")
        return True
    return False


def main():

    # question_type = "prompt_en_Positivity_json"

    parser = argparse.ArgumentParser()
    parser.add_argument("--input_file", type=str, default="../data_cleaning/output/validation_en.csv") #model_training/
    parser.add_argument("--prompt_file_path",type=str)
    parser.add_argument("--output_folder", type=str, default="./outputs/validation/English") #/model_training
    # parser.add_argument("--model", default="gpt-4-1106-preview", type=str)
    parser.add_argument('--output_file',type=str)
    parser.add_argument("--category",type=str)
    # parser.add_argument("--category_cn",type=str,default="氛围")
    parser.add_argument("--language", type = str, default="en")
    parser.add_argument("--prompt_type",type = str, default = "llama/few_shot/rule_based/")
    args = parser.parse_args()
    ### QUESTION: IS df_test the trianing file?
    df_text = pd.read_csv(args.input_file)#, encoding="utf-8", delimiter="\t")
    df_text = df_text.iloc[:]
    print(df_text.shape)
    # print(df_text)
    output_folder = args.output_folder

    Path(output_folder).mkdir(parents=True, exist_ok=True)

    Path(os.path.join(output_folder)).mkdir(parents=True, exist_ok=True)


    pool = multiprocessing.Pool()

    responses = []
    results = pd.DataFrame(columns=['sample_id','national_id','English_Name','Chinese_Name',args.category])

    for restaurant_en, restaurant_cn, sample_id, national_id in tqdm(zip(df_text.English_Name.to_list(), df_text.Chinese_Name.to_list(), df_text.sample_id.to_list(),df_text.national_id.to_list())):
        # concept_name_string = " ".join(concept_name.split("_"))
        if args.language == "en":
            prompt = "./prompts/English/binary/{}.txt".format(args.prompt_type+args.prompt_file_path)
        else:
            prompt = "./prompts/Chinese/binary/{}.txt".format(args.prompt_type+args.prompt_file_path)
        # prompt = "./prompts/English/{}.txt".format(args.prompt_file_path)
        response = pool.apply_async(generate_categorization, args=(restaurant_en, restaurant_cn, prompt, args.language, args.category))
        # print("type===========================================================")
        # print(type(response))
        responses.append([sample_id, national_id, restaurant_en, restaurant_cn, response])
        # print('raw response -------------------------------------')
        # print(responses)

    for sample_id, national_id, restaurant_en, restaurant_cn, response in tqdm(responses):
        results.loc[len(results.index)] = [sample_id, national_id, restaurant_en, restaurant_cn, response.get()]

    results.to_csv(os.path.join(output_folder, args.prompt_type+args.output_file),encoding='utf-8')

    pool.close()
    pool.join()

if __name__ == "__main__":
    # print(is_answer_in_valid_form('1'))
    main()
#     ans = generate_answer("en",'''You will decide whether the name of the restaurant "Boston cafe" belongs to the Ambiance category. 
# If a name classifies as Ambiance, return 1; if not, return 0. 
# As long as a name contains one word that classifies as Ambiance, the entire name classifies as Ambiance. 
# Your response can only be 0 or 1, no other explanation is needed. 

# Here is the criteria for classifying Ambiance:

# Ambiance refers to a kind of atmosphere which makes customers feel comfortable and enjoy the dining experience, or it often indicates family or friendship, or being homesick, which shortens the psychological distance between the restaurant and the patrons. Here are some common examples:
#     - Names containing words like “garden” that conveys a sense of tranquility and leisurely refinement
#     - Name containing words like “palace,” which suggests the image of imperial-style fine dining
#     - Names containing words that describe home-cooked meals in a more casual setting with words like “house,” “home,” “kitchen,” or “dining room”, etc.
#     - Names containing words that evoke images of a simpler life or country living, like “hut”, “village”, “inn”, “bistro”, etc.
#     - Names that contain family members like "Brother", "Uncle", "Grandma", "Mama", etc.
#     - Names words suggesting friendship like "friend", "friendship", etc.
#     - Names containing words related to hometown or home like "Hometown", "Home", etc.

# For instance, "Skewers Hut" contains the word "Hut", which fits the definition of making customers feel comfortable. So your response should be 1. 

# Response: single digit reply''')
    # print(ans)