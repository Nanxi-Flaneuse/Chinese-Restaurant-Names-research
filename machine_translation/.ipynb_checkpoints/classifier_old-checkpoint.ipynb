{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fad0f9-9c30-4317-9944-69e04339272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# !python3 -m pip install openai\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import multiprocessing\n",
    "import re\n",
    "\n",
    "# openai.organization = ''\n",
    "# openai.api_key = ''\n",
    "df = pd.read_csv('sample.csv')\n",
    "df = df.dropna(subset=[\"Chinese_Name\"])\n",
    "df.to_csv('sample.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422fec0-3c61-4a02-a300-22b406180efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_answer_in_valid_form(answer):\n",
    "    \"\"\"Check if the GPT's answer is in the expected format.\n",
    "\n",
    "    This is the format we want:\n",
    "        Readability: 1\n",
    "\n",
    "    Note: 4.5 will be extracted as 4.\n",
    "    \"\"\"\n",
    "    answer = answer.strip(\"\\n\").strip()\n",
    "    if re.search(\"\\w*:\\s?[0-1]\", answer):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def run_gpt4_query(filled_prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= args.model #\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful data science research assistant who speaks both Chinese and English.\"},\n",
    "            {\"role\": \"user\", \"content\": filled_prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(15))\n",
    "\n",
    "### this function prompts the GPT model to generate a response when given a prompt\n",
    "def generate_categorization(restaurant_cn, prompt_file):\n",
    "    \"\"\"Explains a given text for a specific audience.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be explained.\n",
    "        prompt_file (str): The file path to the prompt file.\n",
    "\n",
    "    Returns:\n",
    "        str: The explanation of the input text.\n",
    "\n",
    "    \"\"\"\n",
    "    # Read prompt template\n",
    "    prompt_template = open(prompt_file).read()\n",
    "\n",
    "    # prompt = prompt_template.replace(\"{EN_NAME}\", restaurant_en)\n",
    "    prompt = prompt_template.replace(\"{CN_NAME}\", restaurant_cn)\n",
    "    prompt = prompt.strip(\"\\n\").strip()\n",
    "    prompt = prompt + \"\\n\"\n",
    "    # print(prompt)\n",
    "    while True:\n",
    "        response = run_gpt4_query(prompt)\n",
    "        response = response[\"choices\"][0]['message']['content'].strip(\"\\n\")\n",
    "        return response\n",
    "        # if is_answer_in_valid_form(response):\n",
    "        #     return response\n",
    "        # else:\n",
    "        #     print(\"====>>> Answer not right, re-submitting request...\")\n",
    "\n",
    "\n",
    "    # response = run_gpt4_query(prompt)\n",
    "    # response = response[\"choices\"][0]['message']['content'].strip(\"\\n\")\n",
    "    # return response\n",
    "\n",
    "def main():\n",
    "\n",
    "    # question_type = \"prompt_en_Positivity\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input_file\", type=str, default=\"./boston_sample.csv\")\n",
    "    parser.add_argument(\"--prompt_file_path\", default=\"./prompts/prompt.txt\", type=str)\n",
    "    parser.add_argument(\"--output_folder\", type=str, default=\"./outputs\")\n",
    "    parser.add_argument(\"--model\", default=\"gpt-3.5-turbo-1106\", type=str)\n",
    "    parser.add_argument('--output_file',type=str, defualt = 'positivity.json')\n",
    "    args = parser.parse_args()\n",
    "    ### QUESTION: IS df_test the trianing file?\n",
    "    df_text = pd.read_csv(args.input_file, encoding=\"utf-8\", delimiter=\"\\t\")\n",
    "    df_text = df_text.iloc[:]\n",
    "    print(df_text.shape)\n",
    "    print(df_text)\n",
    "    output_folder = args.output_folder\n",
    "\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # map audience to its full string\n",
    "    short_prompt_folder_name = \"102-doctrines-nonexperts\"\n",
    "    # Path(os.path.join(output_folder, short_prompt_folder_name)).mkdir(parents=True, exist_ok=True)\n",
    "    # Path(os.path.join(output_folder, short_prompt_folder_name, question_type)).mkdir(parents=True, exist_ok=True)\n",
    "    Path(os.path.join(output_folder)).mkdir(parents=True, exist_ok=True)\n",
    "    # Path(os.path.join(output_folder, question_type)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # normal call to debug\n",
    "    # for concept_name, text, story in tqdm(zip(df_text.concept.to_list(), df_text.intro_text.to_list(), df_text.story.to_list())):\n",
    "    #     concept_name = \" \".join(concept_name.split(\"_\"))\n",
    "    #     response = generate_story(text, concept_name, story, args.prompt_file_path)\n",
    "    #     print(response)\n",
    "    #     break\n",
    "\n",
    "    pool = multiprocessing.Pool()\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    for restaurant_en, restaurant_cn, sample_id, national_id in tqdm(zip(df_text.English_Name.to_list(), df_text.Chinese_Name.to_list(), df_text.sample_id.to_list(),df_text.national_id.to_list())):\n",
    "        # concept_name_string = \" \".join(concept_name.split(\"_\"))\n",
    "        response = pool.apply_async(generate_categorization, args=(restaurant_en, restaurant_cn, args.prompt_file_path))\n",
    "        responses.append([sample_id, national_id, restaurant_en, restaurant_cn, response])\n",
    "        print('raw response -------------------------------------')\n",
    "        print(responses)\n",
    "\n",
    "### QUESTION: How do I collect the boolean-value categories of each restaurant? Or can I ask gpt to export a csv file?\n",
    "    for sample_id, national_id, restaurant_en, restaurant_cn, response in tqdm(responses):\n",
    "        json_obj = {\"sample_id\": sample_id, \"national_id\": national_id, \"English_Name\": restaurant_en, \"Chinese_Name\":restaurant_cn}\n",
    "        json_obj[\"Positivity\"] = response.get()\n",
    "        json_obj = json.dumps(json_obj, indent=4)\n",
    "        # with open(os.path.join(output_folder, short_prompt_folder_name, question_type, \"{}.json\".format(concept_name)), \"w\", encoding='UTF-8') as out:\n",
    "        with open(os.path.join(output_folder, args.output_file, \"w\", encoding='UTF-8')) as out:\n",
    "\n",
    "            out.write(json_obj)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
