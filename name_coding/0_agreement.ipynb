{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels\n",
    "# from statsmodels import stats, inter_rater\n",
    "# from stats import inter_rater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for second round testing\n",
    "# nanxi_cn = pd.read_csv(\"annotations/500_2/sample_500_batch2-Nanxi - Chinese-names.csv\")\n",
    "# nanxi_en = pd.read_csv(\"annotations/500_2/sample_500_batch2-Nanxi - English-names.csv\")\n",
    "# nanxi_cn = nanxi_cn.fillna(0)\n",
    "# nanxi_en = nanxi_en.fillna(0)\n",
    "# rukun_cn = pd.read_csv(\"annotations/500_2/sample_500_batch2-Rukun - Chinese-names.csv\")\n",
    "# rukun_en = pd.read_csv(\"annotations/500_2/sample_500_batch2-Rukun - English-names.csv\")\n",
    "# rukun_cn = rukun_cn.fillna(0)\n",
    "# rukun_en = rukun_en.fillna(0)\n",
    "# hang_cn = pd.read_csv(\"annotations/500_2/sample_500_batch2-Hang - Chinese-names.csv\")\n",
    "# hang_en = pd.read_csv(\"annotations/500_2/sample_500_batch2-Hang - English-names.csv\")\n",
    "# hang_cn = hang_cn.fillna(0)\n",
    "# hang_en = hang_en.fillna(0)\n",
    "\n",
    "# # for first round testing\n",
    "# nanxi_cn_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Nanxi - Chinese-names.csv\")\n",
    "# nanxi_en_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Nanxi - English-names.csv\")\n",
    "# nanxi_cn_1 = nanxi_cn_1.fillna(0)\n",
    "# nanxi_en_1 = nanxi_en_1.fillna(0)\n",
    "# rukun_cn_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Rukun - Chinese-names.csv\")\n",
    "# rukun_en_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Rukun - English-names.csv\")\n",
    "# rukun_cn_1 = rukun_cn_1.fillna(0)\n",
    "# rukun_en_1 = rukun_en_1.fillna(0)\n",
    "# hang_cn_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Hang - Chinese-names.csv\")\n",
    "# hang_en_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Hang - English-names.csv\")\n",
    "# hang_cn_1 = hang_cn_1.fillna(0)\n",
    "# hang_en_1 = hang_en_1.fillna(0)\n",
    "\n",
    "# for MA agreement testing\n",
    "# nanxi_cn = pd.read_csv(\"annotations/Round-1-Nanxi-MA - Chinese-names.csv\")\n",
    "# nanxi_en = pd.read_csv(\"annotations/Round-1-Nanxi-MA - English-names.csv\")\n",
    "# nanxi_cn = nanxi_cn.fillna(0)\n",
    "# nanxi_en = nanxi_en.fillna(0)\n",
    "\n",
    "# rukun_cn = pd.read_csv(\"annotations/Round-1-Rukun-MA - Chinese-names.csv\")\n",
    "# rukun_en = pd.read_csv(\"annotations/Round-1-Rukun-MA - English-names.csv\")\n",
    "# rukun_cn = rukun_cn.fillna(0)\n",
    "# rukun_en = rukun_en.fillna(0)\n",
    "\n",
    "# hang_cn = pd.read_csv(\"annotations/Round-1-Hang-MA - Chinese-names.csv\")\n",
    "# hang_en = pd.read_csv(\"annotations/Round-1-Hang-MA - English-names.csv\")\n",
    "# hang_cn = hang_cn.fillna(0)\n",
    "# hang_en = hang_en.fillna(0)\n",
    "\n",
    "# nanxi_cn = pd.concat([nanxi_cn, nanxi_cn_1])\n",
    "# hang_cn = pd.concat([hang_cn, hang_cn_1])\n",
    "# rukun_cn = pd.concat([rukun_cn, rukun_cn_1])\n",
    "# nanxi_en = pd.concat([nanxi_en, nanxi_en_1])\n",
    "# hang_en = pd.concat([hang_en, hang_en_1])\n",
    "# rukun_en = pd.concat([rukun_en, rukun_en_1])\n",
    "# assert nanxi_en.shape[0] == rukun_en.shape[0] == hang_en.shape[0]\n",
    "\n",
    "nanxi_cn = pd.read_csv('annotations/merged_1000_rel/nanxi_cn.csv')\n",
    "nanxi_en = pd.read_csv('annotations/merged_1000_rel/nanxi_en.csv')\n",
    "hang_cn = pd.read_csv('annotations/merged_1000_rel/hang_cn.csv')\n",
    "hang_en = pd.read_csv('annotations/merged_1000_rel/hang_en.csv')\n",
    "rukun_cn = pd.read_csv('annotations/merged_1000_rel/rukun_cn.csv')\n",
    "rukun_en = pd.read_csv('annotations/merged_1000_rel/rukun_en.csv')\n",
    "\n",
    "assert nanxi_cn.shape[0] == nanxi_en.shape[0] == rukun_cn.shape[0] == rukun_en.shape[0] == hang_cn.shape[0] == hang_en.shape[0]\n",
    "# nanxi_en.loc[nanxi_en['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# rukun_en.loc[rukun_en['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# hang_en.loc[hang_en['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# nanxi_cn.loc[nanxi_cn['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# rukun_cn.loc[rukun_cn['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# hang_cn.loc[hang_cn['Relationship'] == 1, 'Ambiance'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_kappa(ann1, ann2):\n",
    "    \"\"\"Computes Cohen kappa for pair-wise annotators.\n",
    "    :param ann1: annotations provided by first annotator\n",
    "    :type ann1: list\n",
    "    :param ann2: annotations provided by second annotator\n",
    "    :type ann2: list\n",
    "    :rtype: float\n",
    "    :return: Cohen kappa statistic\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for an1, an2 in zip(ann1, ann2):\n",
    "        if an1 == an2:\n",
    "            count += 1\n",
    "    A = count / len(ann1)  # observed agreement A (Po)\n",
    "\n",
    "    uniq = set(ann1 + ann2)\n",
    "    E = 0  # expected agreement E (Pe)\n",
    "    for item in uniq:\n",
    "        cnt1 = ann1.count(item)\n",
    "        cnt2 = ann2.count(item)\n",
    "        count = ((cnt1 / len(ann1)) * (cnt2 / len(ann2)))\n",
    "        E += count\n",
    "\n",
    "    return round((A - E) / (1 - E), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hang_cn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  Cohen's Kappa: Personal_Name ===\n",
      "Nanxi-Rukun:  0.813\n",
      "Nanxi-Hang:  0.8283\n",
      "Rukun-Hang:  0.7947\n",
      "Average:  0.8119999999999999\n",
      "\n",
      "===  Cohen's Kappa: Specialty ===\n",
      "Nanxi-Rukun:  0.7853\n",
      "Nanxi-Hang:  0.9156\n",
      "Rukun-Hang:  0.7872\n",
      "Average:  0.8293666666666666\n",
      "\n",
      "===  Cohen's Kappa: Positivity ===\n",
      "Nanxi-Rukun:  0.7749\n",
      "Nanxi-Hang:  0.8812\n",
      "Rukun-Hang:  0.7473\n",
      "Average:  0.8011333333333334\n",
      "\n",
      "===  Cohen's Kappa: Culture ===\n",
      "Nanxi-Rukun:  0.8486\n",
      "Nanxi-Hang:  0.8933\n",
      "Rukun-Hang:  0.8215\n",
      "Average:  0.8544666666666667\n",
      "\n",
      "===  Cohen's Kappa: Location ===\n",
      "Nanxi-Rukun:  0.932\n",
      "Nanxi-Hang:  0.9432\n",
      "Rukun-Hang:  0.9297\n",
      "Average:  0.9349666666666666\n",
      "\n",
      "===  Cohen's Kappa: Ambiance ===\n",
      "Nanxi-Rukun:  0.7873\n",
      "Nanxi-Hang:  0.9005\n",
      "Rukun-Hang:  0.8115\n",
      "Average:  0.8331\n",
      "\n",
      "===  Cohen's Kappa: Pun_Creative ===\n",
      "Nanxi-Rukun:  0.8465\n",
      "Nanxi-Hang:  0.8299\n",
      "Rukun-Hang:  0.8866\n",
      "Average:  0.8543333333333334\n",
      "\n",
      "===  Cohen's Kappa: Romanized ===\n",
      "Nanxi-Rukun:  0.7429\n",
      "Nanxi-Hang:  0.8564\n",
      "Rukun-Hang:  0.7472\n",
      "Average:  0.7821666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# English name coding\n",
    "\n",
    "categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Romanized']\n",
    "df_scores = pd.DataFrame()\n",
    "average = []\n",
    "for category_name in  categories:\n",
    "    nanxi_list = nanxi_en[category_name].astype(int).values.tolist()\n",
    "    rukun_list = rukun_en[category_name].astype(int).values.tolist()\n",
    "    hang_list = hang_en[category_name].astype(int).values.tolist()\n",
    "\n",
    "    print(\"===  Cohen's Kappa:\", category_name, \"===\")\n",
    "\n",
    "    score1 = cohen_kappa(nanxi_list, rukun_list)\n",
    "    score2 = cohen_kappa(nanxi_list, hang_list)\n",
    "    score3 = cohen_kappa(rukun_list, hang_list)\n",
    "    df_scores[category_name] = [score1, score2, score3]\n",
    "    average.append(np.mean([score1, score2, score3]))\n",
    "    print(\"Nanxi-Rukun: \", score1)\n",
    "    print(\"Nanxi-Hang: \", score2)\n",
    "    print(\"Rukun-Hang: \", score3)\n",
    "    print(\"Average: \", np.mean([score1, score2, score3]))\n",
    "    print()\n",
    "\n",
    "df_scores.loc[len(df_scores.index)] = average\n",
    "df_scores = df_scores.round(4)\n",
    "df_scores.to_csv('output/agreement_cohenk_en.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  Cohen's Kappa: Personal_Name ===\n",
      "Nanxi-Rukun:  0.8135\n",
      "Nanxi-Hang:  0.8084\n",
      "Rukun-Hang:  0.8486\n",
      "Average:  0.8235000000000001\n",
      "\n",
      "===  Cohen's Kappa: Specialty ===\n",
      "Nanxi-Rukun:  0.9227\n",
      "Nanxi-Hang:  0.9068\n",
      "Rukun-Hang:  0.8807\n",
      "Average:  0.9034\n",
      "\n",
      "===  Cohen's Kappa: Positivity ===\n",
      "Nanxi-Rukun:  0.7999\n",
      "Nanxi-Hang:  0.8547\n",
      "Rukun-Hang:  0.742\n",
      "Average:  0.7988666666666667\n",
      "\n",
      "===  Cohen's Kappa: Culture ===\n",
      "Nanxi-Rukun:  0.8744\n",
      "Nanxi-Hang:  0.8215\n",
      "Rukun-Hang:  0.8202\n",
      "Average:  0.8386999999999999\n",
      "\n",
      "===  Cohen's Kappa: Location ===\n",
      "Nanxi-Rukun:  0.8687\n",
      "Nanxi-Hang:  0.9221\n",
      "Rukun-Hang:  0.8661\n",
      "Average:  0.8856333333333333\n",
      "\n",
      "===  Cohen's Kappa: Ambiance ===\n",
      "Nanxi-Rukun:  0.8968\n",
      "Nanxi-Hang:  0.8741\n",
      "Rukun-Hang:  0.8655\n",
      "Average:  0.8788\n",
      "\n",
      "===  Cohen's Kappa: Pun_Creative ===\n",
      "Nanxi-Rukun:  0.9285\n",
      "Nanxi-Hang:  0.8661\n",
      "Rukun-Hang:  0.886\n",
      "Average:  0.8935333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chinese name coding\n",
    "\n",
    "categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative']\n",
    "# categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Origin']\n",
    "df_scores_cn = pd.DataFrame()\n",
    "average = []\n",
    "for category_name in  categories:\n",
    "    nanxi_list = nanxi_cn[category_name].astype(int).values.tolist()\n",
    "    rukun_list = rukun_cn[category_name].astype(int).values.tolist()\n",
    "    hang_list = hang_cn[category_name].astype(int).values.tolist()\n",
    "#     df_scores_cn[category_name] = [score1, score2, score3]\n",
    "    print(\"===  Cohen's Kappa:\", category_name, \"===\")\n",
    "\n",
    "    score1 = cohen_kappa(nanxi_list, rukun_list)\n",
    "    score2 = cohen_kappa(nanxi_list, hang_list)\n",
    "    score3 = cohen_kappa(rukun_list, hang_list)\n",
    "    average.append(np.mean([score1, score2, score3]))\n",
    "    print(\"Nanxi-Rukun: \", score1)\n",
    "    print(\"Nanxi-Hang: \", score2)\n",
    "    print(\"Rukun-Hang: \", score3)\n",
    "    print(\"Average: \", np.mean([score1, score2, score3]))\n",
    "    print()\n",
    "    df_scores_cn[category_name] = [score1, score2, score3]\n",
    "\n",
    "df_scores_cn.loc[len(df_scores_cn.index)] = average\n",
    "df_scores_cn = df_scores_cn.round(4)\n",
    "df_scores_cn.to_csv('output/agreement_cohenk_cn.csv', encoding='utf-8')\n",
    "# print(df_scores_cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fleiss Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  Fleiss's Kappa: Personal_Name ===\n",
      "[[3 0]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [1 2]\n",
      " [3 0]]\n",
      "Fleiss English:  0.8119258921028633\n",
      "===  Fleiss's Kappa: Specialty ===\n",
      "[[2 1]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss English:  0.8297380585516178\n",
      "===  Fleiss's Kappa: Positivity ===\n",
      "[[2 1]\n",
      " [3 0]\n",
      " [0 3]\n",
      " ...\n",
      " [0 3]\n",
      " [0 3]\n",
      " [3 0]]\n",
      "Fleiss English:  0.8002442321485231\n",
      "===  Fleiss's Kappa: Culture ===\n",
      "[[3 0]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [2 1]]\n",
      "Fleiss English:  0.8542388052670017\n",
      "===  Fleiss's Kappa: Location ===\n",
      "[[3 0]\n",
      " [0 3]\n",
      " [0 3]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [0 3]]\n",
      "Fleiss English:  0.9349515028304276\n",
      "===  Fleiss's Kappa: Ambiance ===\n",
      "[[2 1]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [0 3]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss English:  0.833710407239819\n",
      "===  Fleiss's Kappa: Pun_Creative ===\n",
      "[[0 3]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss English:  0.8540611930442474\n",
      "===  Fleiss's Kappa: Romanized ===\n",
      "[[3 0]\n",
      " [0 3]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [0 3]]\n",
      "Fleiss English:  0.7840830449826992\n",
      "===  Fleiss's Kappa: Personal_Name ===\n",
      "[[3 0]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss Chinese:  0.8239777250846676\n",
      "===  Fleiss's Kappa: Specialty ===\n",
      "[[3 0]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss Chinese:  0.9032472970915185\n",
      "===  Fleiss's Kappa: Positivity ===\n",
      "[[0 3]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [0 3]\n",
      " [0 3]\n",
      " [3 0]]\n",
      "Fleiss Chinese:  0.7988699125803275\n",
      "===  Fleiss's Kappa: Culture ===\n",
      "[[3 0]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [0 3]]\n",
      "Fleiss Chinese:  0.8380622837370243\n",
      "===  Fleiss's Kappa: Location ===\n",
      "[[3 0]\n",
      " [0 3]\n",
      " [1 2]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss Chinese:  0.885832364716518\n",
      "===  Fleiss's Kappa: Ambiance ===\n",
      "[[3 0]\n",
      " [3 0]\n",
      " [0 3]\n",
      " ...\n",
      " [0 3]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss Chinese:  0.8787420826675392\n",
      "===  Fleiss's Kappa: Pun_Creative ===\n",
      "[[3 0]\n",
      " [3 0]\n",
      " [3 0]\n",
      " ...\n",
      " [3 0]\n",
      " [3 0]\n",
      " [3 0]]\n",
      "Fleiss Chinese:  0.892814457692195\n"
     ]
    }
   ],
   "source": [
    "def get_fleiss(table, method='fleiss'):\n",
    "    table = 1.0 * np.asarray(table)   #avoid integer division\n",
    "    n_sub, n_cat =  table.shape\n",
    "    n_total = table.sum()\n",
    "    n_rater = table.sum(1)\n",
    "    n_rat = n_rater.max()\n",
    "    #assume fully ranked\n",
    "#     assert n_total == n_sub * n_rat\n",
    "\n",
    "    #marginal frequency  of categories\n",
    "    p_cat = table.sum(0) / n_total\n",
    "\n",
    "    table2 = table * table\n",
    "    p_rat = (table2.sum(1) - n_rat) / (n_rat * (n_rat - 1.))\n",
    "    p_mean = p_rat.mean()\n",
    "\n",
    "    if method == 'fleiss':\n",
    "        p_mean_exp = (p_cat*p_cat).sum()\n",
    "    elif method.startswith('rand') or method.startswith('unif'):\n",
    "        p_mean_exp = 1 / n_cat\n",
    "\n",
    "    kappa = (p_mean - p_mean_exp) / (1- p_mean_exp)\n",
    "    return kappa\n",
    "\n",
    "def aggregate_raters(data, n_cat=None):\n",
    "    data = np.asarray(data)\n",
    "    n_rows = data.shape[0]\n",
    "    if n_cat is None:\n",
    "        #I could add int conversion (reverse_index) to np.unique\n",
    "        cat_uni, cat_int = np.unique(data.ravel(), return_inverse=True)\n",
    "        n_cat = len(cat_uni)\n",
    "        data_ = cat_int.reshape(data.shape)\n",
    "    else:\n",
    "        cat_uni = np.arange(n_cat)  #for return only, assumed cat levels\n",
    "        data_ = data\n",
    "\n",
    "    tt = np.zeros((n_rows, n_cat), int)\n",
    "    for idx, row in enumerate(data_):\n",
    "        ro = np.bincount(row)\n",
    "        tt[idx, :len(ro)] = ro\n",
    "\n",
    "    return tt, cat_uni\n",
    "\n",
    "def calculate_fleiss(lang):\n",
    "        if lang == \"en\":\n",
    "            categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Romanized']\n",
    "            # categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Origin']\n",
    "            df_scores = pd.DataFrame()\n",
    "            for category_name in  categories:\n",
    "                nanxi_list = nanxi_en[category_name].astype(int).values.tolist()\n",
    "                rukun_list = rukun_en[category_name].astype(int).values.tolist()\n",
    "                hang_list = hang_en[category_name].astype(int).values.tolist()\n",
    "\n",
    "                print(\"===  Fleiss's Kappa:\", category_name, \"===\")\n",
    "                # compile list for fleiss\n",
    "                raw = np.array([nanxi_list, rukun_list, hang_list]).T\n",
    "#                 print(raw)\n",
    "                # convert data into correct format for fleiss function\n",
    "                table = aggregate_raters(raw,2)[0]\n",
    "                print(table)\n",
    "                fleiss = get_fleiss(table)\n",
    "                df_scores[category_name] = [fleiss]\n",
    "                print(\"Fleiss English: \", fleiss)\n",
    "            df_scores = df_scores.round(4)\n",
    "            df_scores.to_csv('output/fleiss_en.csv', encoding='utf-8')\n",
    "        else:\n",
    "            categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative']\n",
    "            # categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Origin']\n",
    "            df_scores = pd.DataFrame()\n",
    "            for category_name in  categories:\n",
    "                nanxi_list = nanxi_cn[category_name].astype(int).values.tolist()\n",
    "                rukun_list = rukun_cn[category_name].astype(int).values.tolist()\n",
    "                hang_list = hang_cn[category_name].astype(int).values.tolist()\n",
    "\n",
    "                print(\"===  Fleiss's Kappa:\", category_name, \"===\")\n",
    "                # compile list for fleiss\n",
    "                raw = np.array([nanxi_list, rukun_list, hang_list]).T\n",
    "#                 print(raw)\n",
    "                # convert data into correct format for fleiss function\n",
    "                table = aggregate_raters(raw,2)[0]\n",
    "                print(table)\n",
    "                fleiss = get_fleiss(table)\n",
    "                df_scores[category_name] = [fleiss]\n",
    "                print(\"Fleiss Chinese: \", fleiss)\n",
    "            df_scores = df_scores.round(4)\n",
    "            df_scores.to_csv('output/fleiss_cn.csv', encoding='utf-8')\n",
    "\n",
    "calculate_fleiss(\"en\")\n",
    "calculate_fleiss(\"cn\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding different annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled (both index and columns) DataFrame objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     diff\u001b[38;5;241m.\u001b[39mto_excel(filename)\n\u001b[0;32m     11\u001b[0m find_diff(nanxi_cn,rukun_cn,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNR_cn_1.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mfind_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhang_cn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrukun_cn\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHR_cn_1.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m find_diff(hang_cn,nanxi_cn,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHN_cn_1.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mfind_diff\u001b[1;34m(df1, df2, filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_diff\u001b[39m(df1, df2, filename):\n\u001b[1;32m----> 3\u001b[0m     diff \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkeep_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     diff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     diff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChinese_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChinese_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\frame.py:7713\u001b[0m, in \u001b[0;36mDataFrame.compare\u001b[1;34m(self, other, align_axis, keep_shape, keep_equal, result_names)\u001b[0m\n\u001b[0;32m   7591\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   7592\u001b[0m     _shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompare\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   7593\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7711\u001b[0m     result_names: Suffixes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   7712\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 7713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7715\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_equal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_equal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\generic.py:9212\u001b[0m, in \u001b[0;36mNDFrame.compare\u001b[1;34m(self, other, align_axis, keep_shape, keep_equal, result_names)\u001b[0m\n\u001b[0;32m   9207\u001b[0m     cls_self, cls_other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m   9208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   9209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only compare \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_self\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (not \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_other\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_self\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   9210\u001b[0m     )\n\u001b[1;32m-> 9212\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m((\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m) \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misna() \u001b[38;5;241m&\u001b[39m other\u001b[38;5;241m.\u001b[39misna()))\n\u001b[0;32m   9213\u001b[0m mask\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   9215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_equal:\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\frame.py:7442\u001b[0m, in \u001b[0;36mDataFrame._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cmp_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   7440\u001b[0m     axis: Literal[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[1;32m-> 7442\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_method_FRAME\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   7444\u001b[0m     \u001b[38;5;66;03m# See GH#4537 for discussion of scalar op behavior\u001b[39;00m\n\u001b[0;32m   7445\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:313\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[1;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[0;32m    311\u001b[0m             left, right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39malign(right, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39mlevel, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 313\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    314\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled (both index and columns) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    315\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m             )\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, ABCSeries):\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# axis=1 is default for DataFrame-with-Series op\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     axis \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_get_axis_number(axis) \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled (both index and columns) DataFrame objects"
     ]
    }
   ],
   "source": [
    "# compares two people's annotations and exports the differences\n",
    "def find_diff(df1, df2, filename):\n",
    "    diff = df1.compare(df2,keep_shape=True)\n",
    "    diff['English_Name']=df1['English_Name']\n",
    "    diff['Chinese_Name']=df1['Chinese_Name']\n",
    "#     diff = diff.join(df1['English_Name'])\n",
    "#     diff = diff.join(df1['Chinese_Name'])\n",
    "    diff = diff.dropna(thresh = 5)\n",
    "    diff.to_excel(filename)\n",
    "    \n",
    "find_diff(nanxi_cn,rukun_cn,'NR_cn_1.xlsx')\n",
    "find_diff(hang_cn,rukun_cn,'HR_cn_1.xlsx')\n",
    "find_diff(hang_cn,nanxi_cn,'HN_cn_1.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_com(df,filename):\n",
    "    df = df[df['Comments'] != 0]\n",
    "    df.to_csv(filename,encoding='utf-8')\n",
    "# find_com(nanxi_cn,'nanxi_cn_comments.csv')\n",
    "# find_com(nanxi_en,'nanxi_en_comments.csv')\n",
    "# find_com(rukun_cn,'rukun_cn_comments.csv')\n",
    "# find_com(rukun_en,'rukun_en_comments.csv')\n",
    "find_com(hang_en,'hang_en_comments.csv')\n",
    "find_com(hang_cn,'hang_cn_comments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
