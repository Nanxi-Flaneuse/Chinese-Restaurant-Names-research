{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for second round testing\n",
    "nanxi_cn = pd.read_csv(\"annotations/500_2/sample_500_batch2-Nanxi - Chinese-names.csv\")\n",
    "nanxi_en = pd.read_csv(\"annotations/500_2/sample_500_batch2-Nanxi - English-names.csv\")\n",
    "nanxi_cn = nanxi_cn.fillna(0)\n",
    "nanxi_en = nanxi_en.fillna(0)\n",
    "rukun_cn = pd.read_csv(\"annotations/500_2/sample_500_batch2-Rukun - Chinese-names.csv\")\n",
    "rukun_en = pd.read_csv(\"annotations/500_2/sample_500_batch2-Rukun - English-names.csv\")\n",
    "rukun_cn = rukun_cn.fillna(0)\n",
    "rukun_en = rukun_en.fillna(0)\n",
    "hang_cn = pd.read_csv(\"annotations/500_2/sample_500_batch2-Hang - Chinese-names.csv\")\n",
    "hang_en = pd.read_csv(\"annotations/500_2/sample_500_batch2-Hang - English-names.csv\")\n",
    "hang_cn = hang_cn.fillna(0)\n",
    "hang_en = hang_en.fillna(0)\n",
    "\n",
    "# for first round testing\n",
    "nanxi_cn_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Nanxi - Chinese-names.csv\")\n",
    "nanxi_en_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Nanxi - English-names.csv\")\n",
    "nanxi_cn_1 = nanxi_cn_1.fillna(0)\n",
    "nanxi_en_1 = nanxi_en_1.fillna(0)\n",
    "rukun_cn_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Rukun - Chinese-names.csv\")\n",
    "rukun_en_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Rukun - English-names.csv\")\n",
    "rukun_cn_1 = rukun_cn_1.fillna(0)\n",
    "rukun_en_1 = rukun_en_1.fillna(0)\n",
    "hang_cn_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Hang - Chinese-names.csv\")\n",
    "hang_en_1 = pd.read_csv(\"annotations/500/sample_500_batch1-Hang - English-names.csv\")\n",
    "hang_cn_1 = hang_cn_1.fillna(0)\n",
    "hang_en_1 = hang_en_1.fillna(0)\n",
    "\n",
    "# for MA agreement testing\n",
    "# nanxi_cn = pd.read_csv(\"annotations/Round-1-Nanxi-MA - Chinese-names.csv\")\n",
    "# nanxi_en = pd.read_csv(\"annotations/Round-1-Nanxi-MA - English-names.csv\")\n",
    "# nanxi_cn = nanxi_cn.fillna(0)\n",
    "# nanxi_en = nanxi_en.fillna(0)\n",
    "\n",
    "# rukun_cn = pd.read_csv(\"annotations/Round-1-Rukun-MA - Chinese-names.csv\")\n",
    "# rukun_en = pd.read_csv(\"annotations/Round-1-Rukun-MA - English-names.csv\")\n",
    "# rukun_cn = rukun_cn.fillna(0)\n",
    "# rukun_en = rukun_en.fillna(0)\n",
    "\n",
    "# hang_cn = pd.read_csv(\"annotations/Round-1-Hang-MA - Chinese-names.csv\")\n",
    "# hang_en = pd.read_csv(\"annotations/Round-1-Hang-MA - English-names.csv\")\n",
    "# hang_cn = hang_cn.fillna(0)\n",
    "# hang_en = hang_en.fillna(0)\n",
    "\n",
    "nanxi_cn = pd.concat([nanxi_cn, nanxi_cn_1])\n",
    "hang_cn = pd.concat([hang_cn, hang_cn_1])\n",
    "rukun_cn = pd.concat([rukun_cn, rukun_cn_1])\n",
    "nanxi_en = pd.concat([nanxi_en, nanxi_en_1])\n",
    "hang_en = pd.concat([hang_en, hang_en_1])\n",
    "rukun_en = pd.concat([rukun_en, rukun_en_1])\n",
    "# assert nanxi_en.shape[0] == rukun_en.shape[0] == hang_en.shape[0]\n",
    "\n",
    "assert nanxi_cn.shape[0] == nanxi_en.shape[0] == rukun_cn.shape[0] == rukun_en.shape[0] == hang_cn.shape[0] == hang_en.shape[0]\n",
    "# nanxi_en.loc[nanxi_en['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# rukun_en.loc[rukun_en['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# hang_en.loc[hang_en['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# nanxi_cn.loc[nanxi_cn['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# rukun_cn.loc[rukun_cn['Relationship'] == 1, 'Ambiance'] = 1\n",
    "# hang_cn.loc[hang_cn['Relationship'] == 1, 'Ambiance'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_kappa(ann1, ann2):\n",
    "    \"\"\"Computes Cohen kappa for pair-wise annotators.\n",
    "    :param ann1: annotations provided by first annotator\n",
    "    :type ann1: list\n",
    "    :param ann2: annotations provided by second annotator\n",
    "    :type ann2: list\n",
    "    :rtype: float\n",
    "    :return: Cohen kappa statistic\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for an1, an2 in zip(ann1, ann2):\n",
    "        if an1 == an2:\n",
    "            count += 1\n",
    "    A = count / len(ann1)  # observed agreement A (Po)\n",
    "\n",
    "    uniq = set(ann1 + ann2)\n",
    "    E = 0  # expected agreement E (Pe)\n",
    "    for item in uniq:\n",
    "        cnt1 = ann1.count(item)\n",
    "        cnt2 = ann2.count(item)\n",
    "        count = ((cnt1 / len(ann1)) * (cnt2 / len(ann2)))\n",
    "        E += count\n",
    "\n",
    "    return round((A - E) / (1 - E), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hang_cn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  Cohen's Kappa: Personal_Name ===\n",
      "Nanxi-Rukun:  0.8226\n",
      "Nanxi-Hang:  0.8417\n",
      "Rukun-Hang:  0.8055\n",
      "Average:  0.8232666666666666\n",
      "\n",
      "===  Cohen's Kappa: Specialty ===\n",
      "Nanxi-Rukun:  0.7849\n",
      "Nanxi-Hang:  0.9087\n",
      "Rukun-Hang:  0.7932\n",
      "Average:  0.8289333333333334\n",
      "\n",
      "===  Cohen's Kappa: Positivity ===\n",
      "Nanxi-Rukun:  0.7823\n",
      "Nanxi-Hang:  0.8851\n",
      "Rukun-Hang:  0.7505\n",
      "Average:  0.8059666666666666\n",
      "\n",
      "===  Cohen's Kappa: Culture ===\n",
      "Nanxi-Rukun:  0.8812\n",
      "Nanxi-Hang:  0.9097\n",
      "Rukun-Hang:  0.8506\n",
      "Average:  0.8805\n",
      "\n",
      "===  Cohen's Kappa: Location ===\n",
      "Nanxi-Rukun:  0.9317\n",
      "Nanxi-Hang:  0.9416\n",
      "Rukun-Hang:  0.9296\n",
      "Average:  0.9343\n",
      "\n",
      "===  Cohen's Kappa: Ambiance ===\n",
      "Nanxi-Rukun:  0.7989\n",
      "Nanxi-Hang:  0.9068\n",
      "Rukun-Hang:  0.8201\n",
      "Average:  0.8419333333333334\n",
      "\n",
      "===  Cohen's Kappa: Pun_Creative ===\n",
      "Nanxi-Rukun:  0.8469\n",
      "Nanxi-Hang:  0.8303\n",
      "Rukun-Hang:  0.8869\n",
      "Average:  0.8546999999999999\n",
      "\n",
      "===  Cohen's Kappa: Romanized ===\n",
      "Nanxi-Rukun:  0.7548\n",
      "Nanxi-Hang:  0.8588\n",
      "Rukun-Hang:  0.7549\n",
      "Average:  0.7895\n",
      "\n",
      "===  Cohen's Kappa: Relationship ===\n",
      "Nanxi-Rukun:  0.8162\n",
      "Nanxi-Hang:  0.8162\n",
      "Rukun-Hang:  0.8162\n",
      "Average:  0.8161999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# English name coding\n",
    "\n",
    "categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Romanized','Relationship']\n",
    "# categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Origin']\n",
    "df_scores = pd.DataFrame()\n",
    "for category_name in  categories:\n",
    "    nanxi_list = nanxi_en[category_name].astype(int).values.tolist()\n",
    "    rukun_list = rukun_en[category_name].astype(int).values.tolist()\n",
    "    hang_list = hang_en[category_name].astype(int).values.tolist()\n",
    "\n",
    "    print(\"===  Cohen's Kappa:\", category_name, \"===\")\n",
    "\n",
    "    score1 = cohen_kappa(nanxi_list, rukun_list)\n",
    "    score2 = cohen_kappa(nanxi_list, hang_list)\n",
    "    score3 = cohen_kappa(rukun_list, hang_list)\n",
    "    df_scores[category_name] = [score1, score2, score3]\n",
    "    print(\"Nanxi-Rukun: \", score1)\n",
    "    print(\"Nanxi-Hang: \", score2)\n",
    "    print(\"Rukun-Hang: \", score3)\n",
    "    print(\"Average: \", np.mean([score1, score2, score3]))\n",
    "    print()\n",
    "df_scores.to_csv('agreement_all_en.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  Cohen's Kappa: Personal_Name ===\n",
      "Nanxi-Rukun:  0.8181\n",
      "Nanxi-Hang:  0.8186\n",
      "Rukun-Hang:  0.8511\n",
      "Average:  0.8292666666666667\n",
      "\n",
      "===  Cohen's Kappa: Specialty ===\n",
      "Nanxi-Rukun:  0.9124\n",
      "Nanxi-Hang:  0.893\n",
      "Rukun-Hang:  0.8869\n",
      "Average:  0.8974333333333334\n",
      "\n",
      "===  Cohen's Kappa: Positivity ===\n",
      "Nanxi-Rukun:  0.7986\n",
      "Nanxi-Hang:  0.8639\n",
      "Rukun-Hang:  0.7489\n",
      "Average:  0.8038\n",
      "\n",
      "===  Cohen's Kappa: Culture ===\n",
      "Nanxi-Rukun:  0.8965\n",
      "Nanxi-Hang:  0.8485\n",
      "Rukun-Hang:  0.8513\n",
      "Average:  0.8654333333333334\n",
      "\n",
      "===  Cohen's Kappa: Location ===\n",
      "Nanxi-Rukun:  0.8761\n",
      "Nanxi-Hang:  0.9194\n",
      "Rukun-Hang:  0.8689\n",
      "Average:  0.8881333333333333\n",
      "\n",
      "===  Cohen's Kappa: Ambiance ===\n",
      "Nanxi-Rukun:  0.8995\n",
      "Nanxi-Hang:  0.8772\n",
      "Rukun-Hang:  0.865\n",
      "Average:  0.8805666666666667\n",
      "\n",
      "===  Cohen's Kappa: Pun_Creative ===\n",
      "Nanxi-Rukun:  0.9318\n",
      "Nanxi-Hang:  0.8719\n",
      "Rukun-Hang:  0.8911\n",
      "Average:  0.8982666666666667\n",
      "\n",
      "===  Cohen's Kappa: Relationship ===\n",
      "Nanxi-Rukun:  0.8884\n",
      "Nanxi-Hang:  1.0\n",
      "Rukun-Hang:  0.8884\n",
      "Average:  0.9255999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chinese name coding\n",
    "\n",
    "categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Relationship']\n",
    "# categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Origin']\n",
    "df_scores_cn = pd.DataFrame()\n",
    "for category_name in  categories:\n",
    "    nanxi_list = nanxi_cn[category_name].astype(int).values.tolist()\n",
    "    rukun_list = rukun_cn[category_name].astype(int).values.tolist()\n",
    "    hang_list = hang_cn[category_name].astype(int).values.tolist()\n",
    "#     df_scores_cn[category_name] = [score1, score2, score3]\n",
    "    print(\"===  Cohen's Kappa:\", category_name, \"===\")\n",
    "\n",
    "    score1 = cohen_kappa(nanxi_list, rukun_list)\n",
    "    score2 = cohen_kappa(nanxi_list, hang_list)\n",
    "    score3 = cohen_kappa(rukun_list, hang_list)\n",
    "    print(\"Nanxi-Rukun: \", score1)\n",
    "    print(\"Nanxi-Hang: \", score2)\n",
    "    print(\"Rukun-Hang: \", score3)\n",
    "    print(\"Average: \", np.mean([score1, score2, score3]))\n",
    "    print()\n",
    "    df_scores_cn[category_name] = [score1, score2, score3]\n",
    "df_scores_cn.to_csv('agreement_all_cn.csv', encoding='utf-8')\n",
    "# print(df_scores_cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fleiss Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fleiss(table):\n",
    "    return statsmodels.stats.inter_rater.fleiss_kappa(table, method='fleiss')\n",
    "\n",
    "def calculate_fleiss(lang):\n",
    "        if lang === \"en\":\n",
    "            categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Romanized']\n",
    "            # categories = ['Personal_Name', 'Specialty','Positivity', 'Culture', 'Location', 'Ambiance','Pun_Creative','Origin']\n",
    "            df_scores = pd.DataFrame()\n",
    "            for category_name in  categories:\n",
    "                nanxi_list = nanxi_en[category_name].astype(int).values.tolist()\n",
    "                rukun_list = rukun_en[category_name].astype(int).values.tolist()\n",
    "                hang_list = hang_en[category_name].astype(int).values.tolist()\n",
    "\n",
    "                print(\"===  Fleiss's Kappa:\", category_name, \"===\")\n",
    "                # compile list for fleiss\n",
    "                raw = np.array([nanxi_list, rukun_list, hang_list]).T\n",
    "                # convert data into correct format for fleiss function\n",
    "                table = statsmodels.stats.inter_rater.aggregate_raters(raw)\n",
    "                fleiss = get_fleiss(table)\n",
    "                df_scores[category_name] = [fleiss]\n",
    "                print(\"Fleiss: \", fleiss)\n",
    "            df_scores.to_csv('fleiss_en.csv', encoding='utf-8')\n",
    "        else:\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding different annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled (both index and columns) DataFrame objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     diff\u001b[38;5;241m.\u001b[39mto_excel(filename)\n\u001b[0;32m     11\u001b[0m find_diff(nanxi_cn,rukun_cn,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNR_cn_1.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mfind_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhang_cn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrukun_cn\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHR_cn_1.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m find_diff(hang_cn,nanxi_cn,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHN_cn_1.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mfind_diff\u001b[1;34m(df1, df2, filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_diff\u001b[39m(df1, df2, filename):\n\u001b[1;32m----> 3\u001b[0m     diff \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkeep_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     diff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     diff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChinese_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChinese_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\frame.py:7713\u001b[0m, in \u001b[0;36mDataFrame.compare\u001b[1;34m(self, other, align_axis, keep_shape, keep_equal, result_names)\u001b[0m\n\u001b[0;32m   7591\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   7592\u001b[0m     _shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompare\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   7593\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7711\u001b[0m     result_names: Suffixes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   7712\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 7713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7715\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_equal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_equal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\generic.py:9212\u001b[0m, in \u001b[0;36mNDFrame.compare\u001b[1;34m(self, other, align_axis, keep_shape, keep_equal, result_names)\u001b[0m\n\u001b[0;32m   9207\u001b[0m     cls_self, cls_other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m   9208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   9209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only compare \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_self\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (not \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_other\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_self\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   9210\u001b[0m     )\n\u001b[1;32m-> 9212\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m((\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m) \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misna() \u001b[38;5;241m&\u001b[39m other\u001b[38;5;241m.\u001b[39misna()))\n\u001b[0;32m   9213\u001b[0m mask\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   9215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_equal:\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\frame.py:7442\u001b[0m, in \u001b[0;36mDataFrame._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cmp_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   7440\u001b[0m     axis: Literal[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[1;32m-> 7442\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_method_FRAME\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   7444\u001b[0m     \u001b[38;5;66;03m# See GH#4537 for discussion of scalar op behavior\u001b[39;00m\n\u001b[0;32m   7445\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:313\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[1;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[0;32m    311\u001b[0m             left, right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39malign(right, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39mlevel, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 313\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    314\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled (both index and columns) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    315\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m             )\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, ABCSeries):\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# axis=1 is default for DataFrame-with-Series op\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     axis \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_get_axis_number(axis) \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled (both index and columns) DataFrame objects"
     ]
    }
   ],
   "source": [
    "# compares two people's annotations and exports the differences\n",
    "def find_diff(df1, df2, filename):\n",
    "    diff = df1.compare(df2,keep_shape=True)\n",
    "    diff['English_Name']=df1['English_Name']\n",
    "    diff['Chinese_Name']=df1['Chinese_Name']\n",
    "#     diff = diff.join(df1['English_Name'])\n",
    "#     diff = diff.join(df1['Chinese_Name'])\n",
    "    diff = diff.dropna(thresh = 5)\n",
    "    diff.to_excel(filename)\n",
    "    \n",
    "find_diff(nanxi_cn,rukun_cn,'NR_cn_1.xlsx')\n",
    "find_diff(hang_cn,rukun_cn,'HR_cn_1.xlsx')\n",
    "find_diff(hang_cn,nanxi_cn,'HN_cn_1.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "# find_diff(nanxi_cn,rukun_cn,'NR_cn.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_com(df,filename):\n",
    "    df = df[df['Comments'] != 0]\n",
    "    df.to_csv(filename,encoding='utf-8')\n",
    "# find_com(nanxi_cn,'nanxi_cn_comments.csv')\n",
    "# find_com(nanxi_en,'nanxi_en_comments.csv')\n",
    "# find_com(rukun_cn,'rukun_cn_comments.csv')\n",
    "# find_com(rukun_en,'rukun_en_comments.csv')\n",
    "find_com(hang_en,'hang_en_comments.csv')\n",
    "find_com(hang_cn,'hang_cn_comments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
